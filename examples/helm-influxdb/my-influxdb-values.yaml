influxdb:

  ## influxdb image version
  ## ref: https://hub.docker.com/r/library/influxdb/tags/
  image:
    repository: "influxdb"
    tag: "1.8.10-alpine"
    pullPolicy: IfNotPresent
    ## If specified, use these secrets to access the images
    # pullSecrets:
    #   - registry-secret


  serviceAccount:
    create: true
    name:
    annotations: {}

  ## Customize liveness, readiness and startup probes
  ## ref: https://docs.influxdata.com/influxdb/v1.8/tools/api/#ping-http-endpoint
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  ##
  livenessProbe:
    initialDelaySeconds: 30
    path: /ping
    scheme: HTTP
    timeoutSeconds: 5

  readinessProbe:
    initialDelaySeconds: 5
    path: /ping
    scheme: HTTP
    timeoutSeconds: 1

  securityContext: {}
  # runAsUser: 999
  # runAsGroup: 999

  startupProbe:
    enabled: false
    # path: "/ping"
    # failureThreshold: 6
    # periodSeconds: 5
    # scheme: HTTP

  ## Specify a service type and optional port
  ## NodePort is default
  ## ref: http://kubernetes.io/docs/user-guide/services/
  ##
  #service:
  #  externalIPs:
  #    - 10.246.18.95
  #  type: ClusterIP

  service:
    ## Add annotations to service
    # annotations: {}
    type: ClusterIP
    # externalIPs: ["10.246.18.95"]
    # externalTrafficPolicy: ""
    # nodePort(s) value for the LoadBalancer and NodePort service types
    nodePorts:
      http: ""

  ## Persist data to a persistent volume
  ##
  persistence:
    enabled: false
    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    # existingClaim:
    ## influxdb data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: local-storage-retain
    # annotations:
    accessMode: ReadWriteOnce
    size: 10Gi


  ## Set default user
  ##
  setDefaultUser:
    enabled: false
    user:
      ## The user name
      ## Default: "admin"
      username: "admin"

      ## User password
      ## single quotes must be escaped (\')
      ## Default: (Randomly generated 10 characters of AlphaNum)
      # password:

      ## The user name and password are obtained from an existing secret. The expected
      ## keys are `influxdb-user` and `influxdb-password`.
      ## If set, the username and password values above are ignored.
      # existingSecret: influxdb-auth

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources:
    requests:
      memory: 128Mi
      cpu: 0.01
    limits:
      memory: 128Mi
      cpu: 0.1

  # Annotations to be added to InfluxDB pods
  podAnnotations: {}

  # Labels to be added to InfluxDB pods
  podLabels: {}

  ingress:
    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: /
    className: nginx
    enabled: false
    hostname: null
    path: /influx


  ## Add custom volume and volumeMounts
  # volumes:
  #   - name: ssl-cert-volume
  #     secret:
  #       secretName: secret-name
  # mountPoints:
  #   - name: ssl-cert-volume
  #     mountPath: /etc/ssl/certs/selfsigned/
  #     readOnly: true

  ## Additional containers to be added to the pod.
  extraContainers: {}
  #  - name: my-sidecar
  #    image: nginx:latest

  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  # schedulerName:

  ## Node labels for pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  # node-role.kubernetes.io/monitoring: ""

  ## Affinity for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ##
  affinity: {}

  ## Tolerations for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  # - key: "key"
  #   operator: "Equal|Exists"
  #   value: "value"
  #   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

  ## The InfluxDB image uses several environment variables to automatically
  ## configure certain parts of the server.
  ## Ref: https://hub.docker.com/_/influxdb/
  env: []
    # setup TSI indices https://www.influxdata.com/blog/how-to-overcome-memory-usage-challenges-with-the-time-series-index/
    # - name: INFLUXDB_DATA_INDEX_VERSION
    #   value: "tsi1"
    # get dbs curl -G "http://test-influx-influxdb.test-influx:8086/query?pretty=true" --data-urlencode "q=show databases"
    # - name: INFLUXDB_DB
  #   value: "stresstest"

  ## The name of a secret in the same kubernetes namespace which contain values
  ## to be added to the environment.
  ## This can be used, for example, to set the INFLUXDB_HTTP_SHARED_SECRET
  ## environment variable.
  envFromSecret: {}

  ## InfluxDB configuration
  ## ref: https://docs.influxdata.com/influxdb/v1.8/administration/config
  config:
    reporting_disabled: false
    rpc: {}
    meta: {}
    data:
      index-version: "tsi1"
    coordinator: {}
    retention: {}
    shard_precreation: {}
    monitor: {}
    http: {}
    logging: {}
    subscriber: {}
    graphite: {}
    collectd: {}
    opentsdb: {}
    udp: {}
    continuous_queries: {}
    tls: {}

  # Allow executing custom init scripts
  #
  # If the container finds any files with the extensions .sh or .iql inside of the
  # /docker-entrypoint-initdb.d folder, it will execute them. The order they are
  # executed in is determined by the shell. This is usually alphabetical order.
  initScripts:
    enabled: true
    scripts:
      init.iql: |+
        CREATE DATABASE "influxdb" WITH DURATION 14d

  backup:
    enabled: false
    ## By default emptyDir is used as a transitory volume before uploading to object store.
    ## As such, ensure that a sufficient ephemeral storage request is set to prevent node disk filling completely.
    resources:
      requests:
        # memory: 512Mi
        # cpu: 2
        ephemeral-storage: "8Gi"
        # limits:
        # memory: 1Gi
        # cpu: 4
        # ephemeral-storage: "16Gi"
    ## If backup destination is PVC, or want to use intermediate PVC before uploading to object store.
    persistence:
      enabled: false
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      # storageClass: "-"
      annotations:
      accessMode: ReadWriteOnce
      size: 8Gi
    schedule: "0 0 * * *"
    startingDeadlineSeconds: ""
    annotations: {}
    podAnnotations: {}

    ## Google Cloud Storage
    # gcs:
    #    serviceAccountSecret: influxdb-backup-key
    #    serviceAccountSecretKey: key.json
    #    destination: gs://bucket/influxdb

    ## Azure
    ## Secret is expected to have connection string stored in `connection-string` field
    ## Existing container will be used or private one withing storage account will be created.
    # azure:
    #   storageAccountSecret: influxdb-backup-azure-key
    #   destination_container: influxdb-container
    #   destination_path: ""

    ## Amazon S3 or compatible
    ## Secret is expected to have AWS (or compatible) credentials stored in `credentials` field.
    ## Please look at https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html#cli-configure-files-where
    ## for the credentials format.
    ## The bucket should already exist.
    # s3:
    #   credentialsSecret: aws-credentials-secret
    #   destination: s3://bucket/path
    #   ## Optional. Specify if you're using an alternate S3 endpoint.
    #   # endpointUrl: ""

  backupRetention:
    enabled: false
    resources:
      requests:
      # memory: 512Mi
      # cpu: 2
      # limits:
      # memory: 1Gi
      # cpu: 4
    schedule: "0 0 * * *"
    startingDeadlineSeconds:
    annotations: {}
    podAnnotations: {}
    daysToRetain: 7
    # s3:
    #   credentialsSecret: aws-credentials-secret
    #   bucketName: bucket
    #   ## Optional. Specify if you're using an alternate S3 endpoint.
    #   # endpointUrl: ""